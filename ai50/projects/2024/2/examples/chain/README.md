# Markov Chain

Construct a Markov Chain using the `pomegranate` libary with a starting probability and a transition probability matrix

<img src="https://user-images.githubusercontent.com/99038613/179137384-8090b40a-940d-4605-8461-0052312a75a6.jpg" width=60%>

Then use the starting probability to sample an event (rain or sunny), then use the transition probability matrix to sample the event of the future

![3](https://user-images.githubusercontent.com/99038613/179137478-9f3f7b58-d331-404e-bbe9-3c28aaf5a826.jpg)

## How to Use

In `chain` directory, run the command `python model.py`

## What to Learn

The idea of `Markov Chain` as well as `sampling`
